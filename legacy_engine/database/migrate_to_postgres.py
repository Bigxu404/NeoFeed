#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SQLite to PostgreSQL è¿ç§»è„šæœ¬
ç”¨äºŽå°†æœ¬åœ° SQLite æ•°æ®åº“è¿ç§»åˆ° Supabase/PostgreSQL
"""

import sqlite3
import psycopg2
from psycopg2.extras import execute_values
import json
from datetime import datetime


# PostgreSQL Schemaï¼ˆä¸Ž SQLite å¯¹åº”ä½†ä½¿ç”¨ PG ç‰¹æ€§ï¼‰
POSTGRES_SCHEMA = """
-- ============================================
-- NeoFeed æ•°æ®åº“ Schema (PostgreSQL/Supabase ç‰ˆæœ¬)
-- ============================================

-- å¯ç”¨ UUID æ‰©å±•
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- å¯ç”¨ pgvector æ‰©å±•ï¼ˆç”¨äºŽå‘é‡æœç´¢ï¼‰
CREATE EXTENSION IF NOT EXISTS vector;

-- ============================================
-- 1. ç”¨æˆ·è¡¨
-- ============================================
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    email VARCHAR(255) UNIQUE,
    telegram_id VARCHAR(100) UNIQUE,
    telegram_username VARCHAR(100),
    
    preferences JSONB DEFAULT '{"language": "zh-CN", "report_day": "sunday", "report_time": "09:00"}'::jsonb,
    
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_users_telegram ON users(telegram_id);
CREATE INDEX idx_users_email ON users(email);

-- ============================================
-- 2. åŽŸå§‹ä¿¡æ¯è¡¨
-- ============================================
CREATE TABLE items (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    
    title TEXT,
    content TEXT NOT NULL,
    url TEXT,
    
    source_type VARCHAR(50) NOT NULL CHECK(source_type IN ('telegram', 'wechat', 'web', 'gpt', 'manual')),
    source_metadata JSONB,
    
    word_count INTEGER,
    language VARCHAR(10) DEFAULT 'zh',
    
    status VARCHAR(20) DEFAULT 'pending' CHECK(status IN ('pending', 'processed', 'failed')),
    
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_items_user ON items(user_id);
CREATE INDEX idx_items_created ON items(created_at DESC);
CREATE INDEX idx_items_status ON items(status);
CREATE INDEX idx_items_source_type ON items(source_type);

-- å…¨æ–‡æœç´¢ç´¢å¼•
CREATE INDEX idx_items_content_search ON items USING GIN(to_tsvector('simple', content));

-- ============================================
-- 3. AI å¤„ç†ç»“æžœè¡¨
-- ============================================
CREATE TABLE ai_results (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    item_id UUID NOT NULL UNIQUE REFERENCES items(id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    
    summary TEXT,
    
    category VARCHAR(100),
    sub_category VARCHAR(100),
    topics TEXT[],  -- PostgreSQL åŽŸç”Ÿæ•°ç»„
    keywords TEXT[],  -- PostgreSQL åŽŸç”Ÿæ•°ç»„
    
    importance_score FLOAT CHECK(importance_score >= 0 AND importance_score <= 1),
    sentiment VARCHAR(20) CHECK(sentiment IN ('positive', 'neutral', 'negative')),
    
    model_used VARCHAR(50) DEFAULT 'gpt-4o-mini',
    processing_time_ms INTEGER,
    
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_ai_results_item ON ai_results(item_id);
CREATE INDEX idx_ai_results_user ON ai_results(user_id);
CREATE INDEX idx_ai_results_category ON ai_results(category);
CREATE INDEX idx_ai_results_keywords ON ai_results USING GIN(keywords);
CREATE INDEX idx_ai_results_topics ON ai_results USING GIN(topics);

-- ============================================
-- 4. å‘é‡åµŒå…¥è¡¨
-- ============================================
CREATE TABLE embeddings (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    item_id UUID NOT NULL REFERENCES items(id) ON DELETE CASCADE,
    
    embedding vector(1536),  -- OpenAI embedding ç»´åº¦
    
    model VARCHAR(50) DEFAULT 'text-embedding-3-small',
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_embeddings_item_id ON embeddings(item_id);
CREATE INDEX idx_embeddings_vector ON embeddings USING hnsw (embedding vector_cosine_ops);

-- ============================================
-- 5. æ ‡ç­¾è¡¨
-- ============================================
CREATE TABLE tags (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    name VARCHAR(100) NOT NULL,
    category VARCHAR(50),
    color VARCHAR(20) DEFAULT '#3b82f6',
    description TEXT,
    
    created_at TIMESTAMP DEFAULT NOW(),
    
    UNIQUE(user_id, name)
);

CREATE INDEX idx_tags_user ON tags(user_id);

-- ============================================
-- 6. æ¡ç›®-æ ‡ç­¾å…³è”è¡¨
-- ============================================
CREATE TABLE item_tags (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    item_id UUID NOT NULL REFERENCES items(id) ON DELETE CASCADE,
    tag_id UUID NOT NULL REFERENCES tags(id) ON DELETE CASCADE,
    
    created_at TIMESTAMP DEFAULT NOW(),
    
    UNIQUE(item_id, tag_id)
);

CREATE INDEX idx_item_tags_item ON item_tags(item_id);
CREATE INDEX idx_item_tags_tag ON item_tags(tag_id);

-- ============================================
-- 7. å‘¨æŠ¥è¡¨
-- ============================================
CREATE TABLE weekly_reports (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    
    week_start DATE NOT NULL,
    week_end DATE NOT NULL,
    week_range VARCHAR(50),
    
    title TEXT,
    content TEXT,
    summary TEXT,
    
    stats JSONB,
    clusters JSONB,
    insights JSONB,
    keywords_summary JSONB,
    
    item_count INTEGER DEFAULT 0,
    status VARCHAR(20) DEFAULT 'draft' CHECK(status IN ('draft', 'published', 'sent')),
    
    created_at TIMESTAMP DEFAULT NOW(),
    published_at TIMESTAMP,
    sent_at TIMESTAMP
);

CREATE INDEX idx_weekly_reports_user ON weekly_reports(user_id);
CREATE INDEX idx_weekly_reports_dates ON weekly_reports(week_start, week_end);

-- ============================================
-- 8. å‘¨æŠ¥-æ¡ç›®å…³è”è¡¨
-- ============================================
CREATE TABLE report_items (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    report_id UUID NOT NULL REFERENCES weekly_reports(id) ON DELETE CASCADE,
    item_id UUID NOT NULL REFERENCES items(id) ON DELETE CASCADE,
    cluster_name TEXT,
    
    created_at TIMESTAMP DEFAULT NOW(),
    
    UNIQUE(report_id, item_id)
);

CREATE INDEX idx_report_items_report ON report_items(report_id);
CREATE INDEX idx_report_items_item ON report_items(item_id);

-- ============================================
-- 9. å¤„ç†æ—¥å¿—è¡¨
-- ============================================
CREATE TABLE processing_logs (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    item_id UUID REFERENCES items(id) ON DELETE CASCADE,
    
    task_type VARCHAR(50) NOT NULL,
    status VARCHAR(20) NOT NULL CHECK(status IN ('success', 'failed')),
    error_message TEXT,
    retry_count INTEGER DEFAULT 0,
    processing_time_ms INTEGER,
    
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_processing_logs_item ON processing_logs(item_id);
CREATE INDEX idx_processing_logs_status ON processing_logs(status);
"""


def migrate_sqlite_to_postgres(
    sqlite_path='neofeed.db',
    pg_host='localhost',
    pg_port=5432,
    pg_database='neofeed',
    pg_user='postgres',
    pg_password='',
    create_schema=True
):
    """
    å°† SQLite æ•°æ®è¿ç§»åˆ° PostgreSQL
    
    Args:
        sqlite_path: SQLite æ•°æ®åº“è·¯å¾„
        pg_host: PostgreSQL ä¸»æœº
        pg_port: PostgreSQL ç«¯å£
        pg_database: PostgreSQL æ•°æ®åº“å
        pg_user: PostgreSQL ç”¨æˆ·å
        pg_password: PostgreSQL å¯†ç 
        create_schema: æ˜¯å¦åˆ›å»ºè¡¨ç»“æž„
    """
    print("=" * 60)
    print("ðŸ”„ å¼€å§‹æ•°æ®åº“è¿ç§»: SQLite â†’ PostgreSQL")
    print("=" * 60)
    
    # è¿žæŽ¥ SQLite
    print("\nðŸ“‚ è¿žæŽ¥ SQLite æ•°æ®åº“...")
    sqlite_conn = sqlite3.connect(sqlite_path)
    sqlite_conn.row_factory = sqlite3.Row
    sqlite_cursor = sqlite_conn.cursor()
    print("   âœ… SQLite è¿žæŽ¥æˆåŠŸ")
    
    # è¿žæŽ¥ PostgreSQL
    print("\nðŸ˜ è¿žæŽ¥ PostgreSQL æ•°æ®åº“...")
    try:
        pg_conn = psycopg2.connect(
            host=pg_host,
            port=pg_port,
            database=pg_database,
            user=pg_user,
            password=pg_password
        )
        pg_cursor = pg_conn.cursor()
        print("   âœ… PostgreSQL è¿žæŽ¥æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ PostgreSQL è¿žæŽ¥å¤±è´¥: {e}")
        return False
    
    # åˆ›å»ºè¡¨ç»“æž„
    if create_schema:
        print("\nðŸ“‹ åˆ›å»º PostgreSQL è¡¨ç»“æž„...")
        try:
            pg_cursor.execute(POSTGRES_SCHEMA)
            pg_conn.commit()
            print("   âœ… è¡¨ç»“æž„åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"   âš ï¸  è¡¨ç»“æž„åˆ›å»ºè­¦å‘Š: {e}")
            pg_conn.rollback()
    
    # è¿ç§»æ•°æ®
    tables_to_migrate = [
        ('users', ['email', 'telegram_id', 'telegram_username', 'preferences', 'created_at']),
        ('items', ['user_id', 'title', 'content', 'url', 'source_type', 'source_metadata', 
                   'word_count', 'language', 'status', 'created_at']),
        ('ai_results', ['item_id', 'user_id', 'summary', 'category', 'sub_category', 
                        'topics', 'keywords', 'importance_score', 'sentiment', 
                        'model_used', 'processing_time_ms', 'created_at']),
        ('tags', ['user_id', 'name', 'category', 'color', 'description', 'created_at']),
        ('item_tags', ['item_id', 'tag_id', 'created_at']),
        ('weekly_reports', ['user_id', 'week_start', 'week_end', 'week_range', 'title', 
                            'content', 'summary', 'stats', 'clusters', 'insights', 
                            'keywords_summary', 'item_count', 'status', 'created_at']),
        ('report_items', ['report_id', 'item_id', 'cluster_name', 'created_at']),
        ('processing_logs', ['item_id', 'task_type', 'status', 'error_message', 
                             'retry_count', 'processing_time_ms', 'created_at'])
    ]
    
    # ID æ˜ å°„ï¼ˆSQLite INTEGER â†’ PostgreSQL UUIDï¼‰
    id_mappings = {}
    
    for table_name, columns in tables_to_migrate:
        print(f"\nðŸ“¦ è¿ç§»è¡¨: {table_name}")
        
        # ä»Ž SQLite è¯»å–æ•°æ®
        sqlite_cursor.execute(f"SELECT * FROM {table_name}")
        rows = sqlite_cursor.fetchall()
        
        if not rows:
            print(f"   âš ï¸  è¡¨ {table_name} ä¸ºç©ºï¼Œè·³è¿‡")
            continue
        
        print(f"   è¯»å–äº† {len(rows)} æ¡è®°å½•")
        
        # å‡†å¤‡æ’å…¥æ•°æ®
        migrated_count = 0
        for row in rows:
            try:
                # è½¬æ¢æ•°æ®
                values = []
                for col in columns:
                    value = row[col] if col in row.keys() else None
                    
                    # ç‰¹æ®Šå¤„ç†
                    if value is not None:
                        # JSON å­—æ®µ
                        if col in ['preferences', 'source_metadata', 'stats', 'clusters', 'insights', 'keywords_summary']:
                            if isinstance(value, str):
                                value = json.loads(value) if value else None
                        
                        # æ•°ç»„å­—æ®µï¼ˆé€—å·åˆ†éš” â†’ PostgreSQL æ•°ç»„ï¼‰
                        elif col in ['topics', 'keywords'] and isinstance(value, str):
                            value = value.split(',') if value else []
                        
                        # ID æ˜ å°„ï¼ˆå¤–é”®ï¼‰
                        elif col.endswith('_id') and col != 'telegram_id':
                            old_id = value
                            if table_name in ['items'] and col == 'user_id':
                                # ç¬¬ä¸€æ¬¡é‡åˆ° user_idï¼Œéœ€è¦ä»Žæ˜ å°„ä¸­èŽ·å–
                                if 'users' in id_mappings and old_id in id_mappings['users']:
                                    value = id_mappings['users'][old_id]
                    
                    values.append(value)
                
                # æ’å…¥æ•°æ®
                placeholders = ','.join(['%s'] * len(values))
                insert_query = f"INSERT INTO {table_name} ({','.join(columns)}) VALUES ({placeholders}) RETURNING id"
                pg_cursor.execute(insert_query, values)
                
                # ä¿å­˜ ID æ˜ å°„
                new_id = pg_cursor.fetchone()[0]
                if table_name not in id_mappings:
                    id_mappings[table_name] = {}
                id_mappings[table_name][row['id']] = new_id
                
                migrated_count += 1
                
            except Exception as e:
                print(f"   âš ï¸  è¿ç§»è®°å½•å¤±è´¥ (ID: {row['id']}): {e}")
                continue
        
        pg_conn.commit()
        print(f"   âœ… æˆåŠŸè¿ç§» {migrated_count}/{len(rows)} æ¡è®°å½•")
    
    # å…³é—­è¿žæŽ¥
    sqlite_conn.close()
    pg_conn.close()
    
    print("\n" + "=" * 60)
    print("âœ… æ•°æ®è¿ç§»å®Œæˆï¼")
    print("=" * 60)
    print("\nðŸ’¡ æç¤º:")
    print("   - SQLite çš„ INTEGER ID å·²è½¬æ¢ä¸º PostgreSQL çš„ UUID")
    print("   - é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²å·²è½¬æ¢ä¸º PostgreSQL æ•°ç»„")
    print("   - JSON å­—ç¬¦ä¸²å·²è½¬æ¢ä¸º JSONB ç±»åž‹")
    print("   - å¯ä»¥å¼€å§‹ä½¿ç”¨ pgvector è¿›è¡Œå‘é‡æœç´¢äº†")
    
    return True


def export_schema_sql(output_path='postgres_schema.sql'):
    """å¯¼å‡º PostgreSQL schema åˆ°æ–‡ä»¶"""
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(POSTGRES_SCHEMA)
    print(f"âœ… PostgreSQL Schema å·²å¯¼å‡ºåˆ°: {output_path}")


if __name__ == '__main__':
    import sys
    import os
    
    print("=" * 60)
    print("ðŸš€ NeoFeed æ•°æ®åº“è¿ç§»å·¥å…·")
    print("=" * 60)
    print("\né€‰æ‹©æ“ä½œ:")
    print("1. å¯¼å‡º PostgreSQL Schema")
    print("2. æ‰§è¡Œæ•°æ®è¿ç§» (SQLite â†’ PostgreSQL)")
    print("3. ä»…åˆ›å»º PostgreSQL è¡¨ç»“æž„")
    
    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1/2/3): ").strip()
    
    if choice == '1':
        export_schema_sql()
    
    elif choice == '2':
        print("\nè¯·æä¾› PostgreSQL è¿žæŽ¥ä¿¡æ¯:")
        pg_host = input("ä¸»æœº (é»˜è®¤: localhost): ").strip() or 'localhost'
        pg_port = input("ç«¯å£ (é»˜è®¤: 5432): ").strip() or '5432'
        pg_database = input("æ•°æ®åº“å (é»˜è®¤: neofeed): ").strip() or 'neofeed'
        pg_user = input("ç”¨æˆ·å (é»˜è®¤: postgres): ").strip() or 'postgres'
        pg_password = input("å¯†ç : ").strip()
        
        sqlite_path = input("\nSQLite æ•°æ®åº“è·¯å¾„ (é»˜è®¤: neofeed.db): ").strip() or 'neofeed.db'
        
        if not os.path.exists(sqlite_path):
            print(f"âŒ SQLite æ•°æ®åº“ä¸å­˜åœ¨: {sqlite_path}")
            sys.exit(1)
        
        migrate_sqlite_to_postgres(
            sqlite_path=sqlite_path,
            pg_host=pg_host,
            pg_port=int(pg_port),
            pg_database=pg_database,
            pg_user=pg_user,
            pg_password=pg_password,
            create_schema=True
        )
    
    elif choice == '3':
        export_schema_sql('postgres_schema.sql')
        print("\nðŸ’¡ ä½ å¯ä»¥æ‰‹åŠ¨æ‰§è¡Œè¿™ä¸ªæ–‡ä»¶æ¥åˆ›å»ºè¡¨ç»“æž„:")
        print("   psql -U postgres -d neofeed -f postgres_schema.sql")
    
    else:
        print("âŒ æ— æ•ˆçš„é€‰é¡¹")

